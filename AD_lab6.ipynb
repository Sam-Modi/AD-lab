{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPhbq5H/rckXcQjBNMExR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Modi/AD-lab/blob/main/AD_lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q."
      ],
      "metadata": {
        "id": "2ysutGWTU_FZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaLLe90bU55Q",
        "outputId": "e8848e32-a6e5-42be-a428-4539327eaaf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed Results:\n",
            "  Preprocessing              Model  Precision    Recall  F1-Score\n",
            "3            L2                SVM   0.989023  0.988889  0.988869\n",
            "0            L1                SVM   0.987092  0.987037  0.987031\n",
            "6       Scaling                SVM   0.979966  0.979630  0.979535\n",
            "8       Scaling  Gradient Boosting   0.967491  0.966667  0.966775\n",
            "2            L1  Gradient Boosting   0.958436  0.955556  0.956167\n",
            "5            L2  Gradient Boosting   0.948543  0.946296  0.946480\n",
            "4            L2        Naive Bayes   0.871035  0.848148  0.850333\n",
            "1            L1        Naive Bayes   0.869779  0.844444  0.846231\n",
            "7       Scaling        Naive Bayes   0.831033  0.783333  0.780121\n",
            "\n",
            "Efficiency Summary:\n",
            "  Preprocessing  Precision    Recall  F1-Score\n",
            "0            L1   0.938436  0.929012   0.92981\n",
            "1            L2   0.936200  0.927778   0.92856\n",
            "2       Scaling   0.926163  0.909877   0.90881\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the digits dataset\n",
        "data = load_digits()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalization and scaling methods\n",
        "preprocessing_methods = {\n",
        "    'L1': Normalizer(norm='l1'),\n",
        "    'L2': Normalizer(norm='l2'),\n",
        "    'Scaling': StandardScaler()\n",
        "}\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    'SVM': SVC(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Initialize a results dictionary\n",
        "results = []\n",
        "\n",
        "# Iterate through preprocessing techniques\n",
        "for method_name, preprocessor in preprocessing_methods.items():\n",
        "    # Apply preprocessing\n",
        "    if method_name == 'Scaling':\n",
        "        X_train_prep = preprocessor.fit_transform(X_train)\n",
        "        X_test_prep = preprocessor.transform(X_test)\n",
        "    else:\n",
        "        X_train_prep = preprocessor.fit_transform(X_train)\n",
        "        X_test_prep = preprocessor.transform(X_test)\n",
        "\n",
        "    # Iterate through models\n",
        "    for model_name, model in models.items():\n",
        "        # Train the model\n",
        "        model.fit(X_train_prep, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_prep)\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Store the results\n",
        "        results.append({\n",
        "            'Preprocessing': method_name,\n",
        "            'Model': model_name,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Aggregate results by preprocessing method\n",
        "efficiency_summary = results_df.groupby('Preprocessing')[['Precision', 'Recall', 'F1-Score']].mean().reset_index()\n",
        "\n",
        "# Print the results\n",
        "print(\"Detailed Results:\")\n",
        "print(results_df.sort_values(by=['F1-Score'], ascending=False))\n",
        "\n",
        "print(\"\\nEfficiency Summary:\")\n",
        "print(efficiency_summary.sort_values(by=['F1-Score'], ascending=False))\n"
      ]
    }
  ]
}